{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def save_retinanet_to_savedmodel(\n",
    "    backbone_name,\n",
    "    weights_path,\n",
    "    num_classes,\n",
    "    export_path,\n",
    "    preprocessing_mode,\n",
    "    nms=True,\n",
    "    class_specific_filter=True,\n",
    "    anchor_params=None\n",
    "):\n",
    "    import keras\n",
    "    import numpy as np\n",
    "    import tensorflow as tf\n",
    "    from keras_retinanet import models as rn_models\n",
    "    from keras_retinanet.models import retinanet as rn_retinanet\n",
    "    from keras_retinanet.utils import anchors as rn_anchors\n",
    "    from keras_retinanet import layers as rn_layers\n",
    "    \n",
    "    class RetinaNetPreprocessingLayer(keras.layers.Layer):\n",
    "        def __init__(self, preprocessing_mode, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            assert preprocessing_mode in ['caffe', 'tf'], 'Please provide a valid preprocessing mode (caffe or tf).'\n",
    "            self.preprocessing_mode = preprocessing_mode\n",
    "\n",
    "        def call(self, x, **kwargs):\n",
    "            if self.preprocessing_mode == 'caffe':\n",
    "                return x - keras.backend.variable([103.939, 116.779, 123.68])\n",
    "            elif self.preprocessing_mode == 'tf':\n",
    "                return (x - 127.5) / (127.5)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "    # 1. Build and load the model\n",
    "    model = rn_models.backbone(backbone_name=backbone_name).retinanet(num_classes=num_classes)\n",
    "    model.load_weights(weights_path)\n",
    "\n",
    "    # 2. Convert to inference model\n",
    "    model = rn_models.convert_model(\n",
    "        model=model,\n",
    "        nms=nms,\n",
    "        class_specific_filter=class_specific_filter,\n",
    "        anchor_params=anchor_params\n",
    "    )\n",
    "    \n",
    "    # 3. Add helpful names to the output layers.\n",
    "    outputs = [\n",
    "        keras.layers.Lambda(lambda x: keras.backend.tf.identity(x, name='output_boxes'))(model.outputs[0]),\n",
    "        keras.layers.Lambda(lambda x: keras.backend.tf.identity(x, name='output_scores'))(model.outputs[1]),\n",
    "        keras.layers.Lambda(lambda x: keras.backend.tf.identity(x, name='output_labels'))(model.outputs[2]),\n",
    "    ]\n",
    "    model = keras.models.Model(inputs=model.inputs, outputs=outputs, name='retinanet-bbox')\n",
    "\n",
    "    # 4. Add scaling as part of the network. This makes life just a little easier later on.\n",
    "    input_layer = keras.layers.Input(batch_shape=model.input_shape, name='images')\n",
    "    preprocessing_model = keras.models.Model(\n",
    "        inputs=input_layer,\n",
    "        outputs=RetinaNetPreprocessingLayer(preprocessing_mode=preprocessing_mode)(input_layer)\n",
    "    )\n",
    "    model = keras.models.Model(inputs=input_layer, outputs=model(preprocessing_model.outputs))\n",
    "\n",
    "    # 5. Save the model to disk.\n",
    "    if os.path.isdir(export_path):\n",
    "        shutil.rmtree(export_path)\n",
    "    builder = tf.saved_model.builder.SavedModelBuilder(export_path)\n",
    "\n",
    "    signature = tf.saved_model.predict_signature_def(\n",
    "        inputs={'images': model.input},\n",
    "        outputs=dict(zip([o.name[:-2] for o in model.outputs], model.outputs))\n",
    "    )\n",
    "\n",
    "    sess = keras.backend.get_session()\n",
    "    builder.add_meta_graph_and_variables(sess=sess,\n",
    "                                         tags=[tf.saved_model.tag_constants.SERVING],\n",
    "                                         signature_def_map={'predict': signature})\n",
    "    return builder.save()\n",
    "\n",
    "def convert_retinanet_savedmodel_to_tfjs(tf_savedmodel_dir, tfjs_dir):\n",
    "    from tensorflowjs.converters import converter\n",
    "    # 8. In a brand new kernel, convert the saved TensorFlow model to TensorFlowJS format.\n",
    "    if os.path.isdir(tfjs_dir):\n",
    "        shutil.rmtree(tfjs_dir)\n",
    "\n",
    "    converter.tf_saved_model_conversion_v2.convert_tf_saved_model(\n",
    "        saved_model_dir=tf_savedmodel_dir,\n",
    "        output_dir=tfjs_dir,\n",
    "        signature_def='predict',\n",
    "        saved_model_tags='serve',\n",
    "        strip_debug_ops=True\n",
    "    )\n",
    "    model_path = os.path.join(tfjs_dir, 'model.json')\n",
    "    with open(model_path, 'r') as rf:\n",
    "        model_text = rf.read().replace('DT_INT64', 'DT_INT32')\n",
    "    with open(model_path, 'w') as wf:\n",
    "        wf.write(model_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Javascript\n",
    "const modelPath = tfn.io.fileSystem('test_assets/purify_tfjs/model.json');\n",
    "const classes = [\n",
    "    'BELLY_EXPOSED',\n",
    "    'BUTTOCKS_EXPOSED',\n",
    "    'FEMALE_BREAST_EXPOSED',\n",
    "    'FEMALE_BREAST_COVERED',\n",
    "    'FEMALE_GENITALIA_EXPOSED',\n",
    "    'FEMALE_GENITALIA_COVERED',\n",
    "    'MALE_GENITALIA_EXPOSED',\n",
    "    'MALE_BREAST_EXPOSED'\n",
    "];\n",
    "\n",
    "# Python\n",
    "save_retinanet_to_savedmodel(\n",
    "    backbone_name='resnet101',\n",
    "    weights_path='Purify/model/model.h5',\n",
    "    num_classes=8,\n",
    "    export_path='purify_savedmodel',\n",
    "    preprocessing_mode='caffe'\n",
    ")\n",
    "convert_retinanet_savedmodel_to_tfjs(\n",
    "    tf_savedmodel_dir='purify_savedmodel',\n",
    "    tfjs_dir='purify_tfjs'\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# X = np.array([cv2.cvtColor(cv2.imread('test3.jpg'), cv2.COLOR_BGR2RGB)])\n",
    "# y = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
